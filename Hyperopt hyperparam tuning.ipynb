{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb7961af-e70d-41cc-b523-87f101f76150",
   "metadata": {},
   "source": [
    "#### Hyperopt hyperparameters tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27262040-6f7b-48c3-a08e-f54945e829a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    \n",
    "    'n_estimators': 100,\n",
    "    'learning_rate': 0.01, \n",
    "    \n",
    "#     'feature_fraction': 0.75,\n",
    "#     'bagging_fraction': 0.75,\n",
    "#     'bagging_freq': 1,\n",
    "    \n",
    "    'min_gain_to_split': 1e-3,\n",
    "    'reg_lambda': 1e-1,\n",
    "   \n",
    "#     'max_depth': 8,\n",
    "    'num_leaves': 2**5,\n",
    "    'min_data_in_leaf': 2**5, \n",
    "    \n",
    "    'is_unbalance': True,\n",
    "    'importance_type': 'gain',\n",
    "    \n",
    "    'nthread': -1,\n",
    "    'bagging_seed': 42, \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d9b420-0122-45f1-8a5f-e07af01c5aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, hp\n",
    "\n",
    "alpha = 0.5\n",
    "\n",
    "space = {\n",
    "    'n_estimators': hp.choice('n_estimators', list(range(30, 500, 10))),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.001), np.log(0.5)), \n",
    "    'max_depth': hp.quniform('max_depth', 3, 10, 1), \n",
    "    'colsample_bytree': hp.quniform('colsample_bytree', 0.8, 1, 0.01), \n",
    "    'min_child_samples': hp.quniform('min_child_samples', 2, 300, 1), \n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 5),\n",
    "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 5),\n",
    "}\n",
    "\n",
    "def objective(params):\n",
    "    \n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'is_unbalance': True,\n",
    "        'importance_type': 'gain',\n",
    "\n",
    "        'nthread': -1,\n",
    "        'bagging_seed': 42, \n",
    "        \n",
    "        'n_estimators': 100,\n",
    "        'learning_rate': (params['learning_rate']),\n",
    "        'num_leaves': 2**int(params['max_depth']),\n",
    "        'max_depth': int(params['max_depth']),\n",
    "        'colsample_bytree': (params['colsample_bytree']),\n",
    "        'min_child_samples': int(params['min_child_samples']) ,\n",
    "        'reg_lambda': params['reg_lambda'],\n",
    "        'reg_alpha': params['reg_alpha'],\n",
    "    }\n",
    " \n",
    "    model_lgb = lgb.LGBMClassifier(**lgb_params)\n",
    "\n",
    "    model_lgb.fit(\n",
    "        X_train,\n",
    "        y_train, \n",
    "        eval_metric = \"auc\",\n",
    "        # verbose = -1,\n",
    "        # early_stopping_rounds = 10,\n",
    "        eval_set = [(X_train, y_train), (X_test, y_test)]\n",
    "    )\n",
    " \n",
    "    forecast_lgb_test = model_lgb.predict_proba(X_test)[:,1]\n",
    "    score_test = roc_auc_score(y_test, forecast_lgb_test)\n",
    "    \n",
    "    if alpha > 0:\n",
    "        forecast_lgb_train = model_lgb.predict_proba(X_train)[:,1]\n",
    "        score_train = roc_auc_score(y_train, forecast_lgb_train)\n",
    "        \n",
    "        score_total = score_test - alpha * (score_train - score_test)\n",
    "        \n",
    "    else:\n",
    "        score_total = score_test\n",
    "    \n",
    "    print(\"score {:.5f}; params {}\".format(score_test, params))\n",
    "    return -score_total\n",
    "\n",
    "best = fmin(\n",
    "    fn = objective,\n",
    "    space = space,\n",
    "    algo = tpe.suggest,\n",
    "    max_evals = 50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28c7aee-160d-4df5-a53d-24d8f43ba5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e65121-5150-414a-986b-5166e8ca1486",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_lgb_best = lgb.LGBMClassifier(**best)\n",
    "clf_lgb_best\n",
    "\n",
    "# LGBMClassifier(colsample_bytree=0.93, learning_rate=0.10366005116679088,\n",
    "#                max_depth=7.0, min_child_samples=98.0, n_estimators=12,\n",
    "#                reg_alpha=4.396672045765595, reg_lambda=2.0620178916994973)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e9a875-4258-4de0-8427-252bd46544c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_lgb_best = lgb.LGBMClassifier(colsample_bytree=0.93, learning_rate=0.10366005116679088,\n",
    "               max_depth=7, min_child_samples=98, n_estimators=12,\n",
    "               reg_alpha=4.396672045765595, reg_lambda=2.0620178916994973)\n",
    "\n",
    "clf_lgb_best.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049523d0-58db-41b6-9aa2-1b4753e05185",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = model_selection.KFold(n_splits = 4)\n",
    "\n",
    "AUC_cv_best = cross_val_score(clf_lgb_best , X_not_target, y, cv = kfold, scoring = 'roc_auc', n_jobs = -1)\n",
    "AUC_cv_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473dcd8d-2d71-41c5-a37f-4a150551ce41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark 3.5.1",
   "language": "python",
   "name": "pyspark-3.5.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
